{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### V 17:54"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjcCHxkeLKO"
      },
      "source": [
        "### Install initial environment in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRx1SfZkeLKQ",
        "outputId": "7cb88885-ea76-40bf-db14-2c9cdcb1373d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  if not os.path.exists('/content/.already_installed'):\n",
        "    !git clone https://github.com/FlutterbaseDotCom/hdt\n",
        "    !apt-get install -y swig\n",
        "    !pip install -r hdt/requirements.txt\n",
        "    with open('/content/.already_installed', 'w') as f:\n",
        "        f.write('done')\n",
        "  %cd /content/hdt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyFxDs1beLKR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99O1Dp3weLKR",
        "outputId": "caaf2cfe-d075-495a-857b-fa23d9426e62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import wandb\n",
        "from datasets import Dataset, load_dataset\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.torch_layers import NatureCNN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from torch.utils.data import Subset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from dt.configuration_decision_transformer import DecisionTransformerConfig\n",
        "from dt.modeling_decision_transformer import DecisionTransformerModel\n",
        "from extract_cnn import prepare_observation_array\n",
        "from dt.trainable_dt import DecisionTransformerGymDataCollator, TrainableDT\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading file from https://storage.googleapis.com/yakiv-dt-public/datasets/offline_car_racing_150_1000.hdf5 to ./downloaded_datasets/offline_car_racing_150_1000.hdf5\n",
            "Download complete.\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[1;32m/Users/jacob/Documents/T/hdt/DT_train.ipynb Cell 6\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacob/Documents/T/hdt/DT_train.ipynb#X11sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mutils\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mstorage\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mstorage\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/jacob/Documents/T/hdt/DT_train.ipynb#X11sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m features \u001b[39m=\u001b[39m storage\u001b[39m.\u001b[39;49mload_dataset(\u001b[39m'\u001b[39;49m\u001b[39moffline_car_racing_150_1000\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/jacob/Documents/T/hdt/DT_train.ipynb#X11sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39mlen\u001b[39m(features[\u001b[39m\"\u001b[39m\u001b[39mobservations\u001b[39m\u001b[39m\"\u001b[39m]))\n",
            "File \u001b[0;32m~/Documents/T/hdt/utils/storage.py:68\u001b[0m, in \u001b[0;36mload_dataset\u001b[0;34m(dataset_name)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39misfile(dataset_path):\n\u001b[1;32m     66\u001b[0m     download_file(dataset_url, dataset_path)\n\u001b[0;32m---> 68\u001b[0m \u001b[39mreturn\u001b[39;00m load_from_hdf5(dataset_path)\n",
            "File \u001b[0;32m~/Documents/T/hdt/utils/storage.py:24\u001b[0m, in \u001b[0;36mload_from_hdf5\u001b[0;34m(filename)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m hdf5_file\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     23\u001b[0m         group \u001b[39m=\u001b[39m hdf5_file[key]\n\u001b[0;32m---> 24\u001b[0m         data[key] \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39marray(group[\u001b[39mstr\u001b[39m(i)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(group))]\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32m~/Documents/T/hdt/utils/storage.py:24\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m hdf5_file\u001b[39m.\u001b[39mkeys():\n\u001b[1;32m     23\u001b[0m         group \u001b[39m=\u001b[39m hdf5_file[key]\n\u001b[0;32m---> 24\u001b[0m         data[key] \u001b[39m=\u001b[39m [np\u001b[39m.\u001b[39;49marray(group[\u001b[39mstr\u001b[39;49m(i)]) \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39mlen\u001b[39m(group))]\n\u001b[1;32m     25\u001b[0m \u001b[39mreturn\u001b[39;00m data\n",
            "File \u001b[0;32mh5py/_objects.pyx:54\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32mh5py/_objects.pyx:55\u001b[0m, in \u001b[0;36mh5py._objects.with_phil.wrapper\u001b[0;34m()\u001b[0m\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/h5py/_hl/dataset.py:1063\u001b[0m, in \u001b[0;36mDataset.__array__\u001b[0;34m(self, dtype)\u001b[0m\n\u001b[1;32m   1060\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39msize \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[1;32m   1061\u001b[0m     \u001b[39mreturn\u001b[39;00m arr\n\u001b[0;32m-> 1063\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mread_direct(arr)\n\u001b[1;32m   1064\u001b[0m \u001b[39mreturn\u001b[39;00m arr\n",
            "File \u001b[0;32m~/.pyenv/versions/3.10.12/lib/python3.10/site-packages/h5py/_hl/dataset.py:1024\u001b[0m, in \u001b[0;36mDataset.read_direct\u001b[0;34m(self, dest, source_sel, dest_sel)\u001b[0m\n\u001b[1;32m   1021\u001b[0m     dest_sel \u001b[39m=\u001b[39m sel\u001b[39m.\u001b[39mselect(dest\u001b[39m.\u001b[39mshape, dest_sel)\n\u001b[1;32m   1023\u001b[0m \u001b[39mfor\u001b[39;00m mspace \u001b[39min\u001b[39;00m dest_sel\u001b[39m.\u001b[39mbroadcast(source_sel\u001b[39m.\u001b[39marray_shape):\n\u001b[0;32m-> 1024\u001b[0m     \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mid\u001b[39m.\u001b[39;49mread(mspace, fspace, dest, dxpl\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dxpl)\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ],
      "source": [
        "import utils.storage as storage\n",
        "features = storage.load_dataset('offline_car_racing_150_1000')\n",
        "print(len(features[\"observations\"]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [],
      "source": [
        "f1 = load_from_hdf5('./temp_data/features.hdf5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCAF3Q2meLKU"
      },
      "source": [
        "### Persist Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "UqCjWIr2eLKU"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "27648"
            ]
          },
          "execution_count": 16,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "\n",
        "class FeatureDataset(Dataset):\n",
        "    def __init__(self, src):\n",
        "        self.size = len(src[\"observations\"])  # Assuming all lists are the same length\n",
        "        self.src = src\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    \n",
        "    def __getitems__(self, index):\n",
        "        return [self._item(i) for i in index]\n",
        "\n",
        "    def _item(self, idx):\n",
        "        # It is better to ensure this is an internal method used within the class only.\n",
        "        if isinstance(idx, str):\n",
        "            return self.src[idx]\n",
        "        \n",
        "        return {\n",
        "            \"observations\": self.src[\"observations\"][idx],\n",
        "            \"actions\": self.src[\"actions\"][idx], \n",
        "            \"rewards\": self.src[\"rewards\"][idx],\n",
        "            \"dones\": self.src[\"dones\"][idx],\n",
        "            \"rtg\": self.src[\"rtg\"][idx]\n",
        "        }\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        # Here, we use 'index' instead of 'i'\n",
        "        return self._item(index)\n",
        "\n",
        "feature_dataset = FeatureDataset(src=features)\n",
        "len(feature_dataset[0][\"observations\"][0])\n",
        "#dataset.save_to_disk('datasets/car_racing_0070_0045/')\n",
        "\n",
        "# dataset_size = len(dataset)\n",
        "# split_point = int(0.9 * dataset_size)\n",
        "# #dataset is already shuffled\n",
        "# train_dataset = Subset(dataset, range(split_point))\n",
        "# val_dataset = Subset(dataset, range(split_point, dataset_size))\n",
        "\n",
        "#from datasets import load_from_disk\n",
        "#dataset = load_from_disk('datasets/car_racing_002/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "hSYgW1lWeLKU",
        "outputId": "069df814-9e81-41ec-81f9-379007a372ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myakiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/jacob/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/jacob/Documents/T/hdt/wandb/run-20231106_142558-dt_20</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_20' target=\"_blank\">DT_20</a></strong> to <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_20' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/runs/dt_20</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from utils.config import CONFIG, WANDB_ID, WNDB_NAME\n",
        "# TOML-formatted string\n",
        "\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "os.environ['WANDB_NOTEBOOK_NAME'] = 'DT.ipynb'\n",
        "os.environ['WANDB_MODE']='online'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "\n",
        "wandb.login(key=\"f060d3284088ffaf4624e2de8b236f39711a99a2\")\n",
        "wandb.init(resume=WANDB_ID,\n",
        "           name = WNDB_NAME,\n",
        "           mode=\"online\",\n",
        "           entity=\"yakiv\",\n",
        "            project=\"CarRacingDT\",\n",
        "            #resume= \"allow\"\n",
        "            config=CONFIG\n",
        "           )\n",
        "\n",
        "\n",
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmsghw2HeLKV"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "2HyHbWANeLKV",
        "outputId": "12b2da30-ef13-401a-88ae-c59cf2ee5f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action_num': 6, 'state_dim': 27648, 'act_dim': 1, 'hidden_size': 128, 'max_ep_len': 1000, 'action_tanh': True, 'vocab_size': 1, 'n_positions': 1024, 'n_layer': 3, 'n_head': 1, 'n_inner': None, 'activation_function': 'relu', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 50256, 'eos_token_id': 50256, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 10, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', 'transformers_version': '4.34.1', 'model_type': 'decision_transformer'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/2 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[8, 0, 9, 1, 4, 5, 6, 3]\n",
            "Collator sz:8: started at 14:38:52\n",
            "Collator sz:8: finished at 14:38:52 and took 15ms\n",
            "[2, 7]\n",
            "Collator sz:2: started at 14:38:52\n",
            "Collator sz:2: finished at 14:38:52 and took 2ms\n",
            "DecisionTransformerModel.forward batch on device: mps:0 sz:8 seq len: 10 : started at 14:38:52\n",
            "DecisionTransformerModel.forward batch on device: mps:0 sz:8 seq len: 10 : finished at 14:38:52 and took 565ms\n",
            "Trainable Forward pass: started at 14:38:52\n",
            "loss: 1.6918296813964844\n",
            "Trainable Forward pass: finished at 14:38:52 and took 129ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 50%|█████     | 1/2 [00:01<00:01,  2.00s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTransformerModel.forward batch on device: mps:0 sz:2 seq len: 10 : started at 14:38:54\n",
            "DecisionTransformerModel.forward batch on device: mps:0 sz:2 seq len: 10 : finished at 14:38:54 and took 364ms\n",
            "Trainable Forward pass: started at 14:38:54\n",
            "loss: 1.633987307548523\n",
            "Trainable Forward pass: finished at 14:38:54 and took 59ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:02<00:00,  1.38s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 2.9874, 'train_samples_per_second': 3.347, 'train_steps_per_second': 0.669, 'train_loss': 1.6629085540771484, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 2/2 [00:04<00:00,  2.30s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=2, training_loss=1.6629085540771484, metrics={'train_runtime': 2.9874, 'train_samples_per_second': 3.347, 'train_steps_per_second': 0.669, 'train_loss': 1.6629085540771484, 'epoch': 1.0})"
            ]
          },
          "execution_count": 17,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "collator = DecisionTransformerGymDataCollator(feature_dataset, max_len=CONFIG[\"max_length\"],   max_ep_len=CONFIG[\"max_ep_len\"],)\n",
        "\n",
        "dt_config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim,\n",
        "                                      max_length = CONFIG[\"max_length\"],\n",
        "                                      max_ep_len = CONFIG[\"max_ep_len\"],  \n",
        "                                      )\n",
        "print(dt_config.to_dict())\n",
        "\n",
        "model = TrainableDT(dt_config)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output/\",\n",
        "    report_to=\"wandb\",\n",
        "    save_steps=CONFIG[\"save_steps\"],\n",
        "    remove_unused_columns=False,\n",
        "    optim=\"adamw_torch\",\n",
        "    num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=CONFIG[\"per_device_train_batch_size\"],\n",
        "    learning_rate=CONFIG[\"learning_rate\"],\n",
        "    weight_decay=CONFIG[\"weight_decay\"],\n",
        "    warmup_ratio=CONFIG[\"warmup_ratio\"],\n",
        "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
        "    logging_steps=CONFIG[\"LOG_INTERVAL\"],\n",
        ")\n",
        "\n",
        "class DummyDataset(Dataset):\n",
        "    def __init__(self, size):\n",
        "        self.size = size\n",
        "        self.arr = [0] * size\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.size\n",
        "    def __getitems__(self, index):\n",
        "        print(index)\n",
        "        return index\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        print(index)\n",
        "        return index\n",
        "        \n",
        "        \n",
        "\n",
        "    \n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=DummyDataset(len(feature_dataset)),\n",
        "    data_collator=collator,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "#play\n",
        "import matplotlib.pyplot as plt\n",
        "from IPython.display import display as ipy_display, clear_output\n",
        "#import gymnasium as gym\n",
        "# build the environment\n",
        "max_ep_len = 1000\n",
        "device = 'cpu'\n",
        "model = model.to('cpu')\n",
        "scale = 1000.0  # normalization for rewards/returns\n",
        "TARGET_RETURN = 900 / scale  # evaluation is conditioned on a return of 12000, scaled accordingly\n",
        "\n",
        "env =  gym.make('CarRacing-v2', render_mode='rgb_array', continuous=False) #, \n",
        "\n",
        "state_dim = 96*96*3\n",
        "act_dim = 1\n",
        "# Create the decision transformer model\n",
        "\n",
        "# Interact with the environment and create a video\n",
        "episode_return, episode_length = 0, 0\n",
        "[state, _] = env.reset()\n",
        "state = prepare_observation_array(state)\n",
        "target_return = torch.tensor(TARGET_RETURN, device=device, dtype=torch.float32).reshape(1, 1)\n",
        "states = torch.from_numpy(state).reshape(1, state_dim).to(device=device, dtype=torch.float32)\n",
        "actions = torch.zeros((0, act_dim),  device=device, dtype=torch.long)\n",
        "rewards = torch.zeros(0, device=device, dtype=torch.float32)\n",
        "print_every = 10\n",
        "iter = 0\n",
        "\n",
        "timesteps = torch.tensor(0, device=device, dtype=torch.long).reshape(1, 1)\n",
        "for t in range(max_ep_len):\n",
        "    iter += 1\n",
        "    actions = torch.cat([actions, torch.zeros((1, act_dim), dtype=torch.long,  device=device)], dim=0)\n",
        "    rewards = torch.cat([rewards, torch.zeros(1, device=device)])\n",
        "\n",
        "    action = get_action(\n",
        "        model,\n",
        "        states,\n",
        "        actions,\n",
        "        rewards,\n",
        "        target_return,\n",
        "        timesteps,\n",
        "    )\n",
        "    \n",
        "    action =   torch.argmax(action).item() # action.detach().cpu().numpy()\n",
        "    \n",
        "    actions[-1] = torch.tensor(action, dtype=torch.long) \n",
        "\n",
        "    state, reward, done, _, _ = env.step(action)\n",
        "    \n",
        "    if iter % print_every ==0:\n",
        "      image = env.render()\n",
        "      clear_output(wait=True)\n",
        "      plt.imshow(image)\n",
        "      plt.axis('off')  # Hide the axis\n",
        "      display(plt.gcf())\n",
        "    \n",
        "    \n",
        "\n",
        "    state = prepare_observation_array(state)\n",
        "    cur_state = torch.from_numpy(state).to(device=device).reshape(1, state_dim)\n",
        "    states = torch.cat([states, cur_state], dim=0)\n",
        "    rewards[-1] = reward\n",
        "\n",
        "    pred_return = target_return[0, -1] - (reward / scale)\n",
        "    target_return = torch.cat([target_return, pred_return.reshape(1, 1)], dim=1)\n",
        "    timesteps = torch.cat([timesteps, torch.ones((1, 1), device=device, dtype=torch.long) * (t + 1)], dim=1)\n",
        "\n",
        "    episode_return += reward\n",
        "    episode_length += 1\n",
        "\n",
        "    if done:\n",
        "        break"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
