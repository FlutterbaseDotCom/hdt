{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Install initial environment in Google Colab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "if 'google.colab' in sys.modules and  not os.path.exists('/content/.already_installed'):\n",
    "    !git clone https://github.com/FlutterbaseDotCom/hdt\n",
    "    %cd hdt\n",
    "    !apt-get install -y swig\n",
    "    !pip install box2d-py\n",
    "    !pip install 'gymnasium[box2d]'\n",
    "    !pip install 'stable-baselines3[extra]'\n",
    "    !pip install toml\n",
    "    !pip install wandb\n",
    "    !pip install datasets\n",
    "    !pip install transformers\n",
    "    !pip install torchviz\n",
    "    \n",
    "    with open('/content/.already_installed', 'w') as f:\n",
    "        f.write('done')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchviz\n",
    "import wandb\n",
    "from datasets import Dataset, load_dataset\n",
    "from stable_baselines3 import DQN\n",
    "from stable_baselines3.common.torch_layers import NatureCNN\n",
    "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
    "from torch.utils.data import Subset\n",
    "from transformers import Trainer, TrainingArguments\n",
    "\n",
    "from dt.configuration_decision_transformer import DecisionTransformerConfig\n",
    "from dt.modeling_decision_transformer import DecisionTransformerModel\n",
    "from extract_cnn import prepare_observation_array\n",
    "from trainable_dt import DecisionTransformerGymDataCollator, TrainableDT\n",
    "\n",
    "\n",
    "\n",
    "os.environ[\"WANDB_DISABLED\"] = \"true\" "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPISODES = 100\n",
    "MAX_EPISODE_STEPS = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n",
    "model = DQN\n",
    "tmp_model_path ='./models/dql_pretrained/dql_rl_11.zip'\n",
    "loaded_model = model.load(tmp_model_path)\n",
    "\n",
    "features = {\n",
    "    \"observations\": [],\n",
    "    \"actions\": [],\n",
    "    \"rewards\": [],\n",
    "    \"dones\": [],\n",
    "}\n",
    "for episode in range(NUM_EPISODES):\n",
    "    print(f\"Episode: {episode} of {NUM_EPISODES}:\" )\n",
    "    [obs, _] = env.reset()\n",
    "    done = False\n",
    "\n",
    "    o, a, r, d = [], [], [], []\n",
    "    total_reward = 0\n",
    "    sti = 0\n",
    "    while not done:\n",
    "        sti = sti + 1\n",
    "        if sti > MAX_EPISODE_STEPS:\n",
    "            break\n",
    "\n",
    "        # if random.random() < epsilon:\n",
    "        #     action = 3# env.action_space.sample()\n",
    "        # else:\n",
    "        action, _states = loaded_model.predict(obs,deterministic=True)\n",
    "        new_obs, reward, done, t, i = env.step(action)\n",
    "        total_reward = total_reward + reward\n",
    "        oarr = prepare_observation_array(obs)\n",
    "        o.append(oarr.flatten())\n",
    "        a.append(action.item())\n",
    "        r.append(reward)\n",
    "        d.append(done)\n",
    "        obs = new_obs\n",
    "        print(\".\", end=\"\")\n",
    "\n",
    "        # check if last 50 steps does not contain a single positive reward\n",
    "        if len(r) > 100 and max(r[-50:]) <= 0:\n",
    "            # cut last 50 and set done to True\n",
    "            r = r[:-50]\n",
    "            d = d[:-50]\n",
    "            a = a[:-50]\n",
    "            d[-1] = True\n",
    "            print('stopping due to the last 50 steps not negative rewards')\n",
    "            break\n",
    "    print(f\"Total reward: {total_reward} episodes steps: {len(o)}\")\n",
    "    \n",
    "    features[\"observations\"].append(o)\n",
    "    features[\"actions\"].append(a)\n",
    "    features[\"rewards\"].append(r)\n",
    "    features[\"dones\"].append(d)\n",
    "\n",
    "env.close()\n",
    "print(len(features[\"actions\"]))\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Persist Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset.from_dict(features)\n",
    "#dataset.save_to_disk('datasets/car_racing_sm/')\n",
    "\n",
    "# dataset_size = len(dataset)\n",
    "# split_point = int(0.9 * dataset_size)  \n",
    "# #dataset is already shuffled\n",
    "# train_dataset = Subset(dataset, range(split_point))\n",
    "# val_dataset = Subset(dataset, range(split_point, dataset_size))\n",
    "\n",
    "dataset = {\n",
    "    'train': dataset,\n",
    "   # 'validation': val_dataset\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import wandb\n",
    "wandb.login(key=\"f060d3284088ffaf4624e2de8b236f39711a99a2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import toml\n",
    "# TOML-formatted string\n",
    "config_toml = \"\"\"\n",
    "PREFIX              = 'DT'\n",
    "LOG_INTERVAL        = 5\n",
    "save_steps          = 50\n",
    "num_train_epochs    = 1\n",
    "per_device_train_batch_size=64\n",
    "learning_rate       = 0.0001\n",
    "weight_decay        = 0.0001\n",
    "warmup_ratio        = 0.1\n",
    "max_grad_norm       = 0.25\n",
    "\"\"\"\n",
    "\n",
    "config_toml = toml.loads(config_toml)\n",
    "\n",
    "LOAD_SAVED_MODEL    = False\n",
    "\n",
    "RUN_NUM = 15\n",
    "WANDB_ID            = \"dt_\"+str(RUN_NUM)\n",
    "WNDB_NAME           = \"DT_\"+str(RUN_NUM)\n",
    "MODEL_SAVE_NAME     = WNDB_NAME\n",
    "SAVED_MODEL_VERSION = \"latest\"\n",
    "\n",
    "os.environ['WANDB_NOTEBOOK_NAME'] = 'DT.ipynb'\n",
    "os.environ['WANDB_MODE']='online'\n",
    "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
    "os.environ[\"WANDB_DISABLED\"] = \"false\" \n",
    "\n",
    "\n",
    "wandb.init(resume=WANDB_ID,\n",
    "           mode=\"online\",\n",
    "           entity=\"yakiv\",\n",
    "            project=\"CarRacingDT\",\n",
    "            #resume= \"allow\"\n",
    "            config=config_toml\n",
    "           )\n",
    "wandb.run.name = WNDB_NAME\n",
    "\n",
    "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "collator = DecisionTransformerGymDataCollator(dataset[\"train\"])\n",
    "\n",
    "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
    "print(config.to_dict())\n",
    "\n",
    "model = TrainableDT(config)\n",
    "\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"output/\",\n",
    "    report_to=\"wandb\",\n",
    "    save_steps=config_toml[\"save_steps\"],\n",
    "    remove_unused_columns=False,\n",
    "    optim=\"adamw_torch\",\n",
    "    num_train_epochs=config_toml[\"num_train_epochs\"],\n",
    "    per_device_train_batch_size=config_toml[\"per_device_train_batch_size\"],\n",
    "    learning_rate=config_toml[\"learning_rate\"],\n",
    "    weight_decay=config_toml[\"weight_decay\"],\n",
    "    warmup_ratio=config_toml[\"warmup_ratio\"],\n",
    "    max_grad_norm=config_toml[\"max_grad_norm\"],\n",
    "    logging_steps=config_toml[\"LOG_INTERVAL\"],\n",
    ")\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=dataset[\"train\"],\n",
    "    data_collator=collator,\n",
    "\n",
    ")\n",
    "\n",
    "trainer.train()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
