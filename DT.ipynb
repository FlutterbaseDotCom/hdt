{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjcCHxkeLKO"
      },
      "source": [
        "### Install initial environment in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRx1SfZkeLKQ",
        "outputId": "7cb88885-ea76-40bf-db14-2c9cdcb1373d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  if not os.path.exists('/content/.already_installed'):\n",
        "    !git clone https://github.com/FlutterbaseDotCom/hdt\n",
        "\n",
        "    !apt-get install -y swig\n",
        "    !pip install box2d-py\n",
        "    !pip install 'gymnasium[box2d]'\n",
        "    !pip install 'stable-baselines3[extra]'\n",
        "    !pip install toml\n",
        "    !pip install wandb\n",
        "    !pip install datasets\n",
        "    !pip install transformers\n",
        "    !pip install torchviz\n",
        "    !pip install accelerate -U\n",
        "\n",
        "    with open('/content/.already_installed', 'w') as f:\n",
        "        f.write('done')\n",
        "  %cd /content/hdt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyFxDs1beLKR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99O1Dp3weLKR",
        "outputId": "caaf2cfe-d075-495a-857b-fa23d9426e62"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
            "  from .autonotebook import tqdm as notebook_tqdm\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "import wandb\n",
        "from datasets import Dataset, load_dataset\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.torch_layers import NatureCNN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from torch.utils.data import Subset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from dt.configuration_decision_transformer import DecisionTransformerConfig\n",
        "from dt.modeling_decision_transformer import DecisionTransformerModel\n",
        "from extract_cnn import prepare_observation_array\n",
        "from dt.trainable_dt import DecisionTransformerGymDataCollator, TrainableDT\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4p2pRjAeLKS"
      },
      "source": [
        "### Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhM2DabQeLKT",
        "outputId": "21e5d08d-53d4-4b2c-aa0d-9ff8d77d431b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n",
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0 of 70:\n",
            ".............................................\n",
            "Total reward: 6.2142857142857295 episodes steps: 45\n",
            "Episode: 1 of 70:\n",
            ".............................................\n",
            "Total reward: 9.785714285714302 episodes steps: 45\n",
            "Episode: 2 of 70:\n",
            ".............................................\n",
            "Total reward: 9.437282229965172 episodes steps: 45\n",
            "Episode: 3 of 70:\n",
            ".............................................\n",
            "Total reward: 6.7781954887218205 episodes steps: 45\n",
            "Episode: 4 of 70:\n",
            ".............................................\n",
            "Total reward: 9.245704467353967 episodes steps: 45\n",
            "Episode: 5 of 70:\n",
            ".............................................\n",
            "Total reward: 4.875000000000007 episodes steps: 45\n",
            "Episode: 6 of 70:\n",
            ".............................................\n",
            "Total reward: 5.601010101010118 episodes steps: 45\n",
            "Episode: 7 of 70:\n",
            ".............................................\n",
            "Total reward: 3.43650793650795 episodes steps: 45\n",
            "Episode: 8 of 70:\n",
            ".............................................\n",
            "Total reward: 9.734875444839874 episodes steps: 45\n",
            "Episode: 9 of 70:\n",
            ".............................................\n",
            "Total reward: 8.922818791946325 episodes steps: 45\n",
            "Episode: 10 of 70:\n",
            ".............................................\n",
            "Total reward: 9.437282229965172 episodes steps: 45\n",
            "Episode: 11 of 70:\n",
            ".............................................\n",
            "Total reward: 5.146302250803872 episodes steps: 45\n",
            "Episode: 12 of 70:\n",
            ".............................................\n",
            "Total reward: 8.078616352201275 episodes steps: 45\n",
            "Episode: 13 of 70:\n",
            ".............................................\n",
            "Total reward: 10.31481481481483 episodes steps: 45\n",
            "Episode: 14 of 70:\n",
            ".............................................\n",
            "Total reward: 9.198630136986317 episodes steps: 45\n",
            "Episode: 15 of 70:\n",
            ".............................................\n",
            "Total reward: 5.500000000000015 episodes steps: 45\n",
            "Episode: 16 of 70:\n",
            ".............................................\n",
            "Total reward: 8.158227848101282 episodes steps: 45\n",
            "Episode: 17 of 70:\n",
            ".............................................\n",
            "Total reward: 5.46677740863789 episodes steps: 45\n",
            "Episode: 18 of 70:\n",
            ".............................................\n",
            "Total reward: 7.083011583011599 episodes steps: 45\n",
            "Episode: 19 of 70:\n",
            ".............................................\n",
            "Total reward: 2.2340067340067424 episodes steps: 45\n",
            "Episode: 20 of 70:\n",
            ".............................................\n",
            "Total reward: 8.968013468013485 episodes steps: 45\n",
            "Episode: 21 of 70:\n",
            ".............................................\n",
            "Total reward: 7.264705882352956 episodes steps: 45\n",
            "Episode: 22 of 70:\n",
            ".............................................\n",
            "Total reward: 6.529411764705898 episodes steps: 45\n",
            "Episode: 23 of 70:\n",
            ".............................................\n",
            "Total reward: 7.922360248447221 episodes steps: 45\n",
            "Episode: 24 of 70:\n",
            ".............................................\n",
            "Total reward: 10.31481481481483 episodes steps: 45\n",
            "Episode: 25 of 70:\n",
            ".............................................\n",
            "Total reward: 9.486013986014003 episodes steps: 45\n",
            "Episode: 26 of 70:\n",
            ".............................................\n",
            "Total reward: 6.896011396011409 episodes steps: 45\n",
            "Episode: 27 of 70:\n",
            ".............................................\n",
            "Total reward: 9.836917562724032 episodes steps: 45\n",
            "Episode: 28 of 70:\n",
            ".............................................\n",
            "Total reward: 9.340830449827006 episodes steps: 45\n",
            "Episode: 29 of 70:\n",
            ".............................................\n",
            "Total reward: 5.809278350515479 episodes steps: 45\n",
            "Episode: 30 of 70:\n",
            ".............................................\n",
            "Total reward: 7.807692307692324 episodes steps: 45\n",
            "Episode: 31 of 70:\n",
            ".............................................\n",
            "Total reward: 7.695121951219528 episodes steps: 45\n",
            "Episode: 32 of 70:\n",
            ".............................................\n",
            "Total reward: 9.245704467353967 episodes steps: 45\n",
            "Episode: 33 of 70:\n",
            ".............................................\n",
            "Total reward: 6.291366906474835 episodes steps: 45\n",
            "Episode: 34 of 70:\n",
            ".............................................\n",
            "Total reward: 8.83333333333335 episodes steps: 45\n",
            "Episode: 35 of 70:\n",
            ".............................................\n",
            "Total reward: 6.176156583629909 episodes steps: 45\n",
            "Episode: 36 of 70:\n",
            ".............................................\n",
            "Total reward: 9.388888888888905 episodes steps: 45\n",
            "Episode: 37 of 70:\n",
            ".............................................\n",
            "Total reward: 6.778195488721817 episodes steps: 45\n",
            "Episode: 38 of 70:\n",
            ".............................................\n",
            "Total reward: 8.198412698412714 episodes steps: 45\n",
            "Episode: 39 of 70:\n",
            ".............................................\n",
            "Total reward: 8.444983818770243 episodes steps: 45\n",
            "Episode: 40 of 70:\n",
            ".............................................\n",
            "Total reward: 9.992753623188422 episodes steps: 45\n",
            "Episode: 41 of 70:\n",
            ".............................................\n",
            "Total reward: 9.293103448275877 episodes steps: 45\n",
            "Episode: 42 of 70:\n",
            ".............................................\n",
            "Total reward: 8.65789473684212 episodes steps: 45\n",
            "Episode: 43 of 70:\n",
            ".............................................\n",
            "Total reward: 10.31481481481483 episodes steps: 45\n",
            "Episode: 44 of 70:\n",
            ".............................................\n",
            "Total reward: 9.340830449827006 episodes steps: 45\n",
            "Episode: 45 of 70:\n",
            ".............................................\n",
            "Total reward: 8.320512820512837 episodes steps: 45\n",
            "Episode: 46 of 70:\n",
            ".............................................\n",
            "Total reward: 8.320512820512837 episodes steps: 45\n",
            "Episode: 47 of 70:\n",
            ".............................................\n",
            "Total reward: 8.922818791946325 episodes steps: 45\n",
            "Episode: 48 of 70:\n",
            ".............................................\n",
            "Total reward: 8.36173633440516 episodes steps: 45\n",
            "Episode: 49 of 70:\n",
            ".............................................\n",
            "Total reward: 2.100660066006608 episodes steps: 45\n",
            "Episode: 50 of 70:\n",
            ".............................................\n",
            "Total reward: 9.01351351351353 episodes steps: 45\n",
            "Episode: 51 of 70:\n",
            ".............................................\n",
            "Total reward: 7.845679012345693 episodes steps: 45\n",
            "Episode: 52 of 70:\n",
            ".............................................\n",
            "Total reward: 9.888489208633109 episodes steps: 45\n",
            "Episode: 53 of 70:\n",
            ".............................................\n",
            "Total reward: 13.748175182481768 episodes steps: 45\n",
            "Episode: 54 of 70:\n",
            ".............................................\n",
            "Total reward: 10.481273408239716 episodes steps: 45\n",
            "Episode: 55 of 70:\n",
            ".............................................\n",
            "Total reward: 6.6731843575419125 episodes steps: 45\n",
            "Episode: 56 of 70:\n",
            ".............................................\n",
            "Total reward: 6.673184357541913 episodes steps: 45\n",
            "Episode: 57 of 70:\n",
            ".............................................\n",
            "Total reward: 6.138297872340441 episodes steps: 45\n",
            "Episode: 58 of 70:\n",
            ".............................................\n",
            "Total reward: 9.01351351351353 episodes steps: 45\n",
            "Episode: 59 of 70:\n",
            ".............................................\n",
            "Total reward: 8.701320132013217 episodes steps: 45\n",
            "Episode: 60 of 70:\n",
            ".............................................\n",
            "Total reward: 9.198630136986317 episodes steps: 45\n",
            "Episode: 61 of 70:\n",
            ".............................................\n",
            "Total reward: 9.245704467353967 episodes steps: 45\n",
            "Episode: 62 of 70:\n",
            ".............................................\n",
            "Total reward: 8.279552715654969 episodes steps: 45\n",
            "Episode: 63 of 70:\n",
            ".............................................\n",
            "Total reward: 5.303921568627462 episodes steps: 45\n",
            "Episode: 64 of 70:\n",
            ".............................................\n",
            "Total reward: 8.83333333333335 episodes steps: 45\n",
            "Episode: 65 of 70:\n",
            ".............................................\n",
            "Total reward: 9.293103448275877 episodes steps: 45\n",
            "Episode: 66 of 70:\n",
            ".............................................\n",
            "Total reward: 5.952961672473883 episodes steps: 45\n",
            "Episode: 67 of 70:\n",
            ".............................................\n",
            "Total reward: 8.789036544850514 episodes steps: 45\n",
            "Episode: 68 of 70:\n",
            ".............................................\n",
            "Total reward: 9.105442176870763 episodes steps: 45\n",
            "Episode: 69 of 70:\n",
            ".............................................\n",
            "Total reward: 6.928571428571441 episodes steps: 45\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "from utils.config import MAX_EPISODE_STEPS, NUM_EPISODES\n",
        "\n",
        "\n",
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n",
        "model = DQN\n",
        "tmp_model_path ='./models/dql_pretrained/dql_rl_11.zip'\n",
        "loaded_model = model.load(tmp_model_path)\n",
        "\n",
        "features = {\n",
        "    \"observations\": [],\n",
        "    \"actions\": [],\n",
        "    \"rewards\": [],\n",
        "    \"dones\": [],\n",
        "}\n",
        "for episode in range(NUM_EPISODES):\n",
        "    print(f\"Episode: {episode} of {NUM_EPISODES}:\" )\n",
        "    [obs, _] = env.reset()\n",
        "    done = False\n",
        "\n",
        "    o, a, r, d = [], [], [], []\n",
        "    total_reward = 0\n",
        "    sti = 0\n",
        "    while not done:\n",
        "        sti = sti + 1\n",
        "        if sti > MAX_EPISODE_STEPS:\n",
        "            break\n",
        "\n",
        "        # if random.random() < epsilon:\n",
        "        #     action = 3# env.action_space.sample()\n",
        "        # else:\n",
        "        action, _states = loaded_model.predict(obs,deterministic=True)\n",
        "        new_obs, reward, done, t, i = env.step(action)\n",
        "        total_reward = total_reward + reward\n",
        "        oarr = prepare_observation_array(obs)\n",
        "        o.append(oarr.flatten())\n",
        "        a.append(action.item())\n",
        "        r.append(reward)\n",
        "        d.append(done)\n",
        "        obs = new_obs\n",
        "        print(\".\", end=\"\")\n",
        "\n",
        "        # check if last 50 steps does not contain a single positive reward\n",
        "        if len(r) > 100 and max(r[-50:]) <= 0:\n",
        "            # cut last 50 and set done to True\n",
        "            r = r[:-50]\n",
        "            d = d[:-50]\n",
        "            a = a[:-50]\n",
        "            d[-1] = True\n",
        "            print('\\nstopping due to the last 50 steps not negative rewards')\n",
        "            break\n",
        "    print(f\"\\nTotal reward: {total_reward} episodes steps: {len(o)}\")\n",
        "\n",
        "    features[\"observations\"].append(o)\n",
        "    features[\"actions\"].append(a)\n",
        "    features[\"rewards\"].append(r)\n",
        "    features[\"dones\"].append(d)\n",
        "\n",
        "env.close()\n",
        "print(len(features[\"actions\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCAF3Q2meLKU"
      },
      "source": [
        "### Persist Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UqCjWIr2eLKU"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_dict(features)\n",
        "#dataset.save_to_disk('datasets/car_racing_0070_0045/')\n",
        "\n",
        "# dataset_size = len(dataset)\n",
        "# split_point = int(0.9 * dataset_size)\n",
        "# #dataset is already shuffled\n",
        "# train_dataset = Subset(dataset, range(split_point))\n",
        "# val_dataset = Subset(dataset, range(split_point, dataset_size))\n",
        "\n",
        "#from datasets import load_from_disk\n",
        "#dataset = load_from_disk('datasets/car_racing_002/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = {\n",
        "    'train': dataset,\n",
        "   # 'validation': val_dataset\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "hSYgW1lWeLKU",
        "outputId": "069df814-9e81-41ec-81f9-379007a372ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myakiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /Users/jacob/.netrc\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/jacob/Documents/T/hdt/wandb/run-20231106_101927-dt_20</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_20' target=\"_blank\">DT_20</a></strong> to <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_20' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/runs/dt_20</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "from utils.config import CONFIG, WANDB_ID, WNDB_NAME\n",
        "# TOML-formatted string\n",
        "\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "os.environ['WANDB_NOTEBOOK_NAME'] = 'DT.ipynb'\n",
        "os.environ['WANDB_MODE']='online'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "\n",
        "wandb.login(key=\"f060d3284088ffaf4624e2de8b236f39711a99a2\")\n",
        "wandb.init(resume=WANDB_ID,\n",
        "           name = WNDB_NAME,\n",
        "           mode=\"online\",\n",
        "           entity=\"yakiv\",\n",
        "            project=\"CarRacingDT\",\n",
        "            #resume= \"allow\"\n",
        "            config=CONFIG\n",
        "           )\n",
        "\n",
        "\n",
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmsghw2HeLKV"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "2HyHbWANeLKV",
        "outputId": "12b2da30-ef13-401a-88ae-c59cf2ee5f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action_num': 6, 'state_dim': 27648, 'act_dim': 1, 'hidden_size': 128, 'max_ep_len': 1000, 'action_tanh': True, 'vocab_size': 1, 'n_positions': 1024, 'n_layer': 3, 'n_head': 1, 'n_inner': None, 'activation_function': 'relu', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 50256, 'eos_token_id': 50256, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 10, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', 'transformers_version': '4.34.1', 'model_type': 'decision_transformer'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "  0%|          | 0/9 [00:00<?, ?it/s]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:21:16\n",
            "Collator sz:8: finished at 10:21:22 and took 5465ms\n",
            "Collator sz:8: started at 10:21:27\n",
            "Collator sz:8: finished at 10:21:32 and took 5369ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:21:33\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:21:34 and took 1383ms\n",
            "Trainable Forward pass: started at 10:21:34\n",
            "loss: 1.6033169031143188\n",
            "Trainable Forward pass: finished at 10:21:34 and took 219ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 11%|█         | 1/9 [00:25<03:23, 25.41s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:21:40\n",
            "Collator sz:8: finished at 10:21:46 and took 5321ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:21:46\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:21:46 and took 91ms\n",
            "Trainable Forward pass: started at 10:21:46\n",
            "loss: 1.6081148386001587\n",
            "Trainable Forward pass: finished at 10:21:46 and took 87ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 22%|██▏       | 2/9 [00:36<01:58, 16.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:21:51\n",
            "Collator sz:8: finished at 10:21:56 and took 4966ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:21:56\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:21:56 and took 95ms\n",
            "Trainable Forward pass: started at 10:21:56\n",
            "loss: 1.5031492710113525\n",
            "Trainable Forward pass: finished at 10:21:57 and took 91ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 33%|███▎      | 3/9 [00:46<01:23, 13.91s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:22:02\n",
            "Collator sz:8: finished at 10:22:06 and took 4876ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:22:07\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:22:07 and took 91ms\n",
            "Trainable Forward pass: started at 10:22:07\n",
            "loss: 1.4670196771621704\n",
            "Trainable Forward pass: finished at 10:22:07 and took 97ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 44%|████▍     | 4/9 [00:56<01:02, 12.43s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:22:12\n",
            "Collator sz:8: finished at 10:22:17 and took 4957ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:22:17\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:22:17 and took 91ms\n",
            "Trainable Forward pass: started at 10:22:17\n",
            "loss: 1.3986486196517944\n",
            "Trainable Forward pass: finished at 10:22:17 and took 13ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 56%|█████▌    | 5/9 [01:07<00:46, 11.69s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'loss': 1.516, 'learning_rate': 5e-05, 'epoch': 0.56}\n",
            "Collator sz:8: started at 10:22:22\n",
            "Collator sz:8: finished at 10:22:27 and took 4875ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:22:27\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:22:27 and took 95ms\n",
            "Trainable Forward pass: started at 10:22:27\n",
            "loss: 1.416059136390686\n",
            "Trainable Forward pass: finished at 10:22:27 and took 86ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 67%|██████▋   | 6/9 [01:17<00:33, 11.20s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:8: started at 10:22:32\n",
            "Collator sz:8: finished at 10:22:37 and took 5057ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:22:38\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:22:38 and took 90ms\n",
            "Trainable Forward pass: started at 10:22:38\n",
            "loss: 1.3473986387252808\n",
            "Trainable Forward pass: finished at 10:22:38 and took 82ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 78%|███████▊  | 7/9 [01:27<00:21, 10.92s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collator sz:6: started at 10:22:42\n",
            "Collator sz:6: finished at 10:22:45 and took 3741ms\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : started at 10:22:45\n",
            "DecisionTransformerModel.forward batch sz:8 seq len: 10 : finished at 10:22:46 and took 87ms\n",
            "Trainable Forward pass: started at 10:22:46\n",
            "loss: 1.5513800382614136\n",
            "Trainable Forward pass: finished at 10:22:46 and took 46ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            " 89%|████████▉ | 8/9 [01:35<00:09,  9.95s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DecisionTransformerModel.forward batch sz:6 seq len: 10 : started at 10:22:46\n",
            "DecisionTransformerModel.forward batch sz:6 seq len: 10 : finished at 10:22:46 and took 326ms\n",
            "Trainable Forward pass: started at 10:22:46\n",
            "loss: 1.4486445188522339\n",
            "Trainable Forward pass: finished at 10:22:46 and took 116ms\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [01:36<00:00,  7.10s/it]"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'train_runtime': 96.5809, 'train_samples_per_second': 0.725, 'train_steps_per_second': 0.093, 'train_loss': 1.4826368755764432, 'epoch': 1.0}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 9/9 [01:38<00:00, 10.91s/it]\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "TrainOutput(global_step=9, training_loss=1.4826368755764432, metrics={'train_runtime': 96.5809, 'train_samples_per_second': 0.725, 'train_steps_per_second': 0.093, 'train_loss': 1.4826368755764432, 'epoch': 1.0})"
            ]
          },
          "execution_count": 8,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "\n",
        "collator = DecisionTransformerGymDataCollator(dataset[\"train\"], max_len=CONFIG[\"max_length\"],   max_ep_len=CONFIG[\"max_ep_len\"],)\n",
        "\n",
        "dt_config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim,\n",
        "                                      max_length = CONFIG[\"max_length\"],\n",
        "                                      max_ep_len = CONFIG[\"max_ep_len\"],  \n",
        "                                      )\n",
        "print(dt_config.to_dict())\n",
        "\n",
        "model = TrainableDT(dt_config)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output/\",\n",
        "    report_to=\"wandb\",\n",
        "    save_steps=CONFIG[\"save_steps\"],\n",
        "    remove_unused_columns=False,\n",
        "    optim=\"adamw_torch\",\n",
        "    num_train_epochs=CONFIG[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=CONFIG[\"per_device_train_batch_size\"],\n",
        "    learning_rate=CONFIG[\"learning_rate\"],\n",
        "    weight_decay=CONFIG[\"weight_decay\"],\n",
        "    warmup_ratio=CONFIG[\"warmup_ratio\"],\n",
        "    max_grad_norm=CONFIG[\"max_grad_norm\"],\n",
        "    logging_steps=CONFIG[\"LOG_INTERVAL\"],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    data_collator=collator,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
