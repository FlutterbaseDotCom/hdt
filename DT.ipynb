{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjcCHxkeLKO"
      },
      "source": [
        "### Install initial environment in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRx1SfZkeLKQ",
        "outputId": "7cb88885-ea76-40bf-db14-2c9cdcb1373d"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  if not os.path.exists('/content/.already_installed'):\n",
        "    !git clone https://github.com/FlutterbaseDotCom/hdt\n",
        "\n",
        "    !apt-get install -y swig\n",
        "    !pip install box2d-py\n",
        "    !pip install 'gymnasium[box2d]'\n",
        "    !pip install 'stable-baselines3[extra]'\n",
        "    !pip install toml\n",
        "    !pip install wandb\n",
        "    !pip install datasets\n",
        "    !pip install transformers\n",
        "    !pip install torchviz\n",
        "    !pip install accelerate -U\n",
        "\n",
        "    with open('/content/.already_installed', 'w') as f:\n",
        "        f.write('done')\n",
        "  %cd /content/hdt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyFxDs1beLKR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99O1Dp3weLKR",
        "outputId": "caaf2cfe-d075-495a-857b-fa23d9426e62"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "import wandb\n",
        "from datasets import Dataset, load_dataset\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.torch_layers import NatureCNN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from torch.utils.data import Subset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from dt.configuration_decision_transformer import DecisionTransformerConfig\n",
        "from dt.modeling_decision_transformer import DecisionTransformerModel\n",
        "from extract_cnn import prepare_observation_array\n",
        "from dt.trainable_dt import DecisionTransformerGymDataCollator, TrainableDT\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4p2pRjAeLKS"
      },
      "source": [
        "### Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZBnsAYfeLKT",
        "outputId": "63570422-b37c-46dd-a72a-407e5731290a"
      },
      "outputs": [],
      "source": [
        "NUM_EPISODES = 70\n",
        "MAX_EPISODE_STEPS = 40"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhM2DabQeLKT",
        "outputId": "21e5d08d-53d4-4b2c-aa0d-9ff8d77d431b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object lr_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n",
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/stable_baselines3/common/save_util.py:166: UserWarning: Could not deserialize object exploration_schedule. Consider using `custom_objects` argument to replace this object.\n",
            "Exception: Can't get attribute '_make_function' on <module 'cloudpickle.cloudpickle' from '/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/cloudpickle/cloudpickle.py'>\n",
            "  warnings.warn(\n",
            "/Users/jacob/.pyenv/versions/3.10.12/lib/python3.10/site-packages/stable_baselines3/common/buffers.py:231: UserWarning: This system does not have apparently enough memory to store the complete replay buffer 8.30GB > 7.24GB\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Episode: 0 of 70:\n",
            "........................................\n",
            "Total reward: 12.000000000000014 episodes steps: 40\n",
            "Episode: 1 of 70:\n",
            "........................................\n",
            "Total reward: 5.966777408637888 episodes steps: 40\n",
            "Episode: 2 of 70:\n",
            "........................................\n",
            "Total reward: 3.462686567164191 episodes steps: 40\n",
            "Episode: 3 of 70:\n",
            "........................................\n",
            "Total reward: 8.383900928792585 episodes steps: 40\n",
            "Episode: 4 of 70:\n",
            "........................................\n",
            "Total reward: 11.267175572519099 episodes steps: 40\n",
            "Episode: 5 of 70:\n",
            "........................................\n",
            "Total reward: 5.55414012738855 episodes steps: 40\n",
            "Episode: 6 of 70:\n",
            "........................................\n",
            "Total reward: 8.698412698412712 episodes steps: 40\n",
            "Episode: 7 of 70:\n",
            "........................................\n",
            "Total reward: 9.745704467353965 episodes steps: 40\n",
            "Episode: 8 of 70:\n",
            "........................................\n",
            "Total reward: 10.2857142857143 episodes steps: 40\n",
            "Episode: 9 of 70:\n",
            "........................................\n",
            "Total reward: 11.094339622641524 episodes steps: 40\n",
            "Episode: 10 of 70:\n",
            "........................................\n",
            "Total reward: 8.820512820512837 episodes steps: 40\n",
            "Episode: 11 of 70:\n",
            "........................................\n",
            "Total reward: 6.309278350515477 episodes steps: 40\n",
            "Episode: 12 of 70:\n",
            "........................................\n",
            "Total reward: 2.688963210702349 episodes steps: 40\n",
            "Episode: 13 of 70:\n",
            "........................................\n",
            "Total reward: 9.698630136986315 episodes steps: 40\n",
            "Episode: 14 of 70:\n",
            "........................................\n",
            "Total reward: 11.151515151515168 episodes steps: 40\n",
            "Episode: 15 of 70:\n",
            "........................................\n",
            "Total reward: 9.029315960912067 episodes steps: 40\n",
            "Episode: 16 of 70:\n",
            "........................................\n",
            "Total reward: 10.54545454545456 episodes steps: 40\n",
            "Episode: 17 of 70:\n",
            "........................................\n",
            "Total reward: 10.76014760147603 episodes steps: 40\n",
            "Episode: 18 of 70:\n",
            "........................................\n",
            "Total reward: 10.084507042253536 episodes steps: 40\n",
            "Episode: 19 of 70:\n",
            "........................................\n",
            "Total reward: 4.771929824561418 episodes steps: 40\n",
            "Episode: 20 of 70:\n",
            "........................................\n",
            "Total reward: 9.559322033898319 episodes steps: 40\n",
            "Episode: 21 of 70:\n",
            "........................................\n",
            "Total reward: 6.169491525423743 episodes steps: 40\n",
            "Episode: 22 of 70:\n",
            "........................................\n",
            "Total reward: 7.320754716981146 episodes steps: 40\n",
            "Episode: 23 of 70:\n",
            "........................................\n",
            "Total reward: 5.646302250803868 episodes steps: 40\n",
            "Episode: 24 of 70:\n",
            "........................................\n",
            "Total reward: 10.814814814814829 episodes steps: 40\n",
            "Episode: 25 of 70:\n",
            "........................................\n",
            "Total reward: 9.745704467353965 episodes steps: 40\n",
            "Episode: 26 of 70:\n",
            "........................................\n",
            "Total reward: 7.5384615384615525 episodes steps: 40\n",
            "Episode: 27 of 70:\n",
            "........................................\n",
            "Total reward: 7.904761904761919 episodes steps: 40\n",
            "Episode: 28 of 70:\n",
            "........................................\n",
            "Total reward: 5.433962264150958 episodes steps: 40\n",
            "Episode: 29 of 70:\n",
            "........................................\n",
            "Total reward: 9.377926421404696 episodes steps: 40\n",
            "Episode: 30 of 70:\n",
            "........................................\n",
            "Total reward: 10.981273408239714 episodes steps: 40\n",
            "Episode: 31 of 70:\n",
            "........................................\n",
            "Total reward: 6.204081632653075 episodes steps: 40\n",
            "Episode: 32 of 70:\n",
            "........................................\n",
            "Total reward: 8.779552715654967 episodes steps: 40\n",
            "Episode: 33 of 70:\n",
            "........................................\n",
            "Total reward: 8.820512820512835 episodes steps: 40\n",
            "Episode: 34 of 70:\n",
            "........................................\n",
            "Total reward: 11.686274509803935 episodes steps: 40\n",
            "Episode: 35 of 70:\n",
            "........................................\n",
            "Total reward: 10.440433212996403 episodes steps: 40\n",
            "Episode: 36 of 70:\n",
            "........................................\n",
            "Total reward: 9.11475409836067 episodes steps: 40\n",
            "Episode: 37 of 70:\n",
            "........................................\n",
            "Total reward: 7.7647058823529544 episodes steps: 40\n",
            "Episode: 38 of 70:\n",
            "........................................\n",
            "Total reward: 9.651877133105817 episodes steps: 40\n",
            "Episode: 39 of 70:\n",
            "........................................\n",
            "Total reward: 10.54545454545456 episodes steps: 40\n",
            "Episode: 40 of 70:\n",
            "........................................\n",
            "Total reward: 9.157894736842119 episodes steps: 40\n",
            "Episode: 41 of 70:\n",
            "........................................\n",
            "Total reward: 8.500000000000014 episodes steps: 40\n",
            "Episode: 42 of 70:\n",
            "........................................\n",
            "Total reward: 9.793103448275874 episodes steps: 40\n",
            "Episode: 43 of 70:\n",
            "........................................\n",
            "Total reward: 9.559322033898319 episodes steps: 40\n",
            "Episode: 44 of 70:\n",
            "........................................\n",
            "Total reward: 8.944983818770242 episodes steps: 40\n",
            "Episode: 45 of 70:\n",
            "........................................\n",
            "Total reward: 8.307692307692323 episodes steps: 40\n",
            "Episode: 46 of 70:\n",
            "........................................\n",
            "Total reward: 9.651877133105819 episodes steps: 40\n",
            "Episode: 47 of 70:\n",
            "........................................\n",
            "Total reward: 10.18439716312058 episodes steps: 40\n",
            "Episode: 48 of 70:\n",
            "........................................\n",
            "Total reward: 10.134275618374572 episodes steps: 40\n",
            "Episode: 49 of 70:\n",
            "........................................\n",
            "Total reward: 8.269938650306763 episodes steps: 40\n",
            "Episode: 50 of 70:\n",
            "........................................\n",
            "Total reward: 11.625000000000014 episodes steps: 40\n",
            "Episode: 51 of 70:\n",
            "........................................\n",
            "Total reward: 9.986013986014001 episodes steps: 40\n",
            "Episode: 52 of 70:\n",
            "........................................\n",
            "Total reward: 7.406844106463893 episodes steps: 40\n",
            "Episode: 53 of 70:\n",
            "........................................\n",
            "Total reward: 6.676156583629908 episodes steps: 40\n",
            "Episode: 54 of 70:\n",
            "........................................\n",
            "Total reward: 7.811023622047259 episodes steps: 40\n",
            "Episode: 55 of 70:\n",
            "........................................\n",
            "Total reward: 6.067114093959746 episodes steps: 40\n",
            "Episode: 56 of 70:\n",
            "........................................\n",
            "Total reward: 9.986013986014001 episodes steps: 40\n",
            "Episode: 57 of 70:\n",
            "........................................\n",
            "Total reward: 10.54545454545456 episodes steps: 40\n",
            "Episode: 58 of 70:\n",
            "........................................\n",
            "Total reward: 2.5789473684210598 episodes steps: 40\n",
            "Episode: 59 of 70:\n",
            "........................................\n",
            "Total reward: 3.9681274900398544 episodes steps: 40\n",
            "Episode: 60 of 70:\n",
            "........................................\n",
            "Total reward: 4.264462809917369 episodes steps: 40\n",
            "Episode: 61 of 70:\n",
            "........................................\n",
            "Total reward: 8.65822784810128 episodes steps: 40\n",
            "Episode: 62 of 70:\n",
            "........................................\n",
            "Total reward: 10.925373134328373 episodes steps: 40\n",
            "Episode: 63 of 70:\n",
            "........................................\n",
            "Total reward: 8.578616352201273 episodes steps: 40\n",
            "Episode: 64 of 70:\n",
            "........................................\n",
            "Total reward: 11.748031496063007 episodes steps: 40\n",
            "Episode: 65 of 70:\n",
            "........................................\n",
            "Total reward: 11.564202334630364 episodes steps: 40\n",
            "Episode: 66 of 70:\n",
            "........................................\n",
            "Total reward: 5.036144578313268 episodes steps: 40\n",
            "Episode: 67 of 70:\n",
            "........................................\n",
            "Total reward: 8.944983818770242 episodes steps: 40\n",
            "Episode: 68 of 70:\n",
            "........................................\n",
            "Total reward: 8.820512820512835 episodes steps: 40\n",
            "Episode: 69 of 70:\n",
            "........................................\n",
            "Total reward: 3.7220077220077346 episodes steps: 40\n",
            "70\n"
          ]
        }
      ],
      "source": [
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n",
        "model = DQN\n",
        "tmp_model_path ='./models/dql_pretrained/dql_rl_11.zip'\n",
        "loaded_model = model.load(tmp_model_path)\n",
        "\n",
        "features = {\n",
        "    \"observations\": [],\n",
        "    \"actions\": [],\n",
        "    \"rewards\": [],\n",
        "    \"dones\": [],\n",
        "}\n",
        "for episode in range(NUM_EPISODES):\n",
        "    print(f\"Episode: {episode} of {NUM_EPISODES}:\" )\n",
        "    [obs, _] = env.reset()\n",
        "    done = False\n",
        "\n",
        "    o, a, r, d = [], [], [], []\n",
        "    total_reward = 0\n",
        "    sti = 0\n",
        "    while not done:\n",
        "        sti = sti + 1\n",
        "        if sti > MAX_EPISODE_STEPS:\n",
        "            break\n",
        "\n",
        "        # if random.random() < epsilon:\n",
        "        #     action = 3# env.action_space.sample()\n",
        "        # else:\n",
        "        action, _states = loaded_model.predict(obs,deterministic=True)\n",
        "        new_obs, reward, done, t, i = env.step(action)\n",
        "        total_reward = total_reward + reward\n",
        "        oarr = prepare_observation_array(obs)\n",
        "        o.append(oarr.flatten())\n",
        "        a.append(action.item())\n",
        "        r.append(reward)\n",
        "        d.append(done)\n",
        "        obs = new_obs\n",
        "        print(\".\", end=\"\")\n",
        "\n",
        "        # check if last 50 steps does not contain a single positive reward\n",
        "        if len(r) > 100 and max(r[-50:]) <= 0:\n",
        "            # cut last 50 and set done to True\n",
        "            r = r[:-50]\n",
        "            d = d[:-50]\n",
        "            a = a[:-50]\n",
        "            d[-1] = True\n",
        "            print('\\nstopping due to the last 50 steps not negative rewards')\n",
        "            break\n",
        "    print(f\"\\nTotal reward: {total_reward} episodes steps: {len(o)}\")\n",
        "\n",
        "    features[\"observations\"].append(o)\n",
        "    features[\"actions\"].append(a)\n",
        "    features[\"rewards\"].append(r)\n",
        "    features[\"dones\"].append(d)\n",
        "\n",
        "env.close()\n",
        "print(len(features[\"actions\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCAF3Q2meLKU"
      },
      "source": [
        "### Persist Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "UqCjWIr2eLKU"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Saving the dataset (1/1 shards): 100%|██████████| 70/70 [00:04<00:00, 17.21 examples/s]\n"
          ]
        }
      ],
      "source": [
        "dataset = Dataset.from_dict(features)\n",
        "dataset.save_to_disk('datasets/car_racing_0070_0040/')\n",
        "\n",
        "# dataset_size = len(dataset)\n",
        "# split_point = int(0.9 * dataset_size)\n",
        "# #dataset is already shuffled\n",
        "# train_dataset = Subset(dataset, range(split_point))\n",
        "# val_dataset = Subset(dataset, range(split_point, dataset_size))\n",
        "\n",
        "#from datasets import load_from_disk\n",
        "#dataset = load_from_disk('datasets/car_racing_002/')\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Split dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "dataset = {\n",
        "    'train': dataset,\n",
        "   # 'validation': val_dataset\n",
        "}\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "hSYgW1lWeLKU",
        "outputId": "069df814-9e81-41ec-81f9-379007a372ec"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Calling wandb.login() after wandb.init() has no effect.\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "Finishing last run (ID:dt_16) before initializing another..."
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Waiting for W&B process to finish... <strong style=\"color:green\">(success).</strong>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run <strong style=\"color:#cdcd00\">DT_16</strong> at: <a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_16' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/runs/dt_16</a><br/> View job at <a href='https://wandb.ai/yakiv/CarRacingDT/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMjgzNzkwOQ==/version_details/v0' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/jobs/QXJ0aWZhY3RDb2xsZWN0aW9uOjExMjgzNzkwOQ==/version_details/v0</a><br/>Synced 5 W&B file(s), 0 media file(s), 2 artifact file(s) and 0 other file(s)"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Find logs at: <code>./wandb/run-20231105_210839-dt_16/logs</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Successfully finished last run (ID:dt_16). Initializing new run:<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Run data is saved locally in <code>/Users/jacob/Documents/T/hdt/wandb/run-20231105_212126-dt_17</code>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "Syncing run <strong><a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_17' target=\"_blank\">DT_17</a></strong> to <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View project at <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              " View run at <a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_17' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/runs/dt_17</a>"
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "import toml\n",
        "# TOML-formatted string\n",
        "config_toml = \"\"\"\n",
        "PREFIX              = 'DT'\n",
        "LOG_INTERVAL        = 5\n",
        "save_steps          = 50\n",
        "num_train_epochs    = 1\n",
        "per_device_train_batch_size=64\n",
        "learning_rate       = 0.0001\n",
        "weight_decay        = 0.0001\n",
        "warmup_ratio        = 0.1\n",
        "max_grad_norm       = 0.25\n",
        "\"\"\"\n",
        "\n",
        "config_toml = toml.loads(config_toml)\n",
        "\n",
        "LOAD_SAVED_MODEL    = False\n",
        "\n",
        "RUN_NUM = 17\n",
        "WANDB_ID            = \"dt_\"+str(RUN_NUM)\n",
        "WNDB_NAME           = \"DT_\"+str(RUN_NUM)\n",
        "MODEL_SAVE_NAME     = WNDB_NAME\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "os.environ['WANDB_NOTEBOOK_NAME'] = 'DT.ipynb'\n",
        "os.environ['WANDB_MODE']='online'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "\n",
        "\n",
        "wandb.login(key=\"f060d3284088ffaf4624e2de8b236f39711a99a2\")\n",
        "wandb.init(resume=WANDB_ID,\n",
        "           name = WNDB_NAME,\n",
        "           mode=\"online\",\n",
        "           entity=\"yakiv\",\n",
        "            project=\"CarRacingDT\",\n",
        "            #resume= \"allow\"\n",
        "            config=config_toml\n",
        "           )\n",
        "\n",
        "\n",
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmsghw2HeLKV"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "2HyHbWANeLKV",
        "outputId": "12b2da30-ef13-401a-88ae-c59cf2ee5f5e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{'action_num': 5, 'state_dim': 27648, 'act_dim': 1, 'hidden_size': 128, 'max_ep_len': 4096, 'action_tanh': True, 'vocab_size': 1, 'n_positions': 1024, 'n_layer': 3, 'n_head': 1, 'n_inner': None, 'activation_function': 'relu', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 50256, 'eos_token_id': 50256, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', 'transformers_version': '4.34.1', 'model_type': 'decision_transformer'}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": []
        }
      ],
      "source": [
        "\n",
        "\n",
        "collator = DecisionTransformerGymDataCollator(dataset[\"train\"])\n",
        "\n",
        "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
        "print(config.to_dict())\n",
        "\n",
        "model = TrainableDT(config)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output/\",\n",
        "    report_to=\"wandb\",\n",
        "    save_steps=config_toml[\"save_steps\"],\n",
        "    remove_unused_columns=False,\n",
        "    optim=\"adamw_torch\",\n",
        "    num_train_epochs=config_toml[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=config_toml[\"per_device_train_batch_size\"],\n",
        "    learning_rate=config_toml[\"learning_rate\"],\n",
        "    weight_decay=config_toml[\"weight_decay\"],\n",
        "    warmup_ratio=config_toml[\"warmup_ratio\"],\n",
        "    max_grad_norm=config_toml[\"max_grad_norm\"],\n",
        "    logging_steps=config_toml[\"LOG_INTERVAL\"],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    data_collator=collator,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "V100",
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.12"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
