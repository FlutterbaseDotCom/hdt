{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xpjcCHxkeLKO"
      },
      "source": [
        "### Install initial environment in Google Colab"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GRx1SfZkeLKQ",
        "outputId": "7cb88885-ea76-40bf-db14-2c9cdcb1373d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/hdt\n"
          ]
        }
      ],
      "source": [
        "import sys\n",
        "import os\n",
        "\n",
        "if 'google.colab' in sys.modules:\n",
        "  if not os.path.exists('/content/.already_installed'):\n",
        "    !git clone https://github.com/FlutterbaseDotCom/hdt\n",
        "\n",
        "    !apt-get install -y swig\n",
        "    !pip install box2d-py\n",
        "    !pip install 'gymnasium[box2d]'\n",
        "    !pip install 'stable-baselines3[extra]'\n",
        "    !pip install toml\n",
        "    !pip install wandb\n",
        "    !pip install datasets\n",
        "    !pip install transformers\n",
        "    !pip install torchviz\n",
        "    !pip install accelerate -U\n",
        "\n",
        "    with open('/content/.already_installed', 'w') as f:\n",
        "        f.write('done')\n",
        "  %cd /content/hdt\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tyFxDs1beLKR"
      },
      "source": [
        "### Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "99O1Dp3weLKR",
        "outputId": "caaf2cfe-d075-495a-857b-fa23d9426e62"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/tensorflow/python/framework/dtypes.py:35: DeprecationWarning: ml_dtypes.float8_e4m3b11 is deprecated. Use ml_dtypes.float8_e4m3b11fnuz\n",
            "  from tensorflow.tsl.python.lib.core import pywrap_ml_dtypes\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import random\n",
        "from dataclasses import dataclass\n",
        "\n",
        "import gymnasium as gym\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torchviz\n",
        "import wandb\n",
        "from datasets import Dataset, load_dataset\n",
        "from stable_baselines3 import DQN\n",
        "from stable_baselines3.common.torch_layers import NatureCNN\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv, VecTransposeImage\n",
        "from torch.utils.data import Subset\n",
        "from transformers import Trainer, TrainingArguments\n",
        "\n",
        "from dt.configuration_decision_transformer import DecisionTransformerConfig\n",
        "from dt.modeling_decision_transformer import DecisionTransformerModel\n",
        "from extract_cnn import prepare_observation_array\n",
        "from trainable_dt import DecisionTransformerGymDataCollator, TrainableDT\n",
        "\n",
        "\n",
        "\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F4p2pRjAeLKS"
      },
      "source": [
        "### Generate Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XZBnsAYfeLKT",
        "outputId": "63570422-b37c-46dd-a72a-407e5731290a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        }
      ],
      "source": [
        "NUM_EPISODES = 10\n",
        "MAX_EPISODE_STEPS = 1000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UhM2DabQeLKT",
        "outputId": "21e5d08d-53d4-4b2c-aa0d-9ff8d77d431b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Episode: 0 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 862.0253164556891 episodes steps: 1000\n",
            "Episode: 1 of 10:\n",
            "...................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "stopping due to the last 50 steps not negative rewards\n",
            "\n",
            "Total reward: 902.0999999999922 episodes steps: 979\n",
            "Episode: 2 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 896.6101694915131 episodes steps: 1000\n",
            "Episode: 3 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 870.6959706959628 episodes steps: 1000\n",
            "Episode: 4 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 899.9999999999861 episodes steps: 1000\n",
            "Episode: 5 of 10:\n",
            "...............................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "stopping due to the last 50 steps not negative rewards\n",
            "\n",
            "Total reward: 509.5915750915707 episodes steps: 655\n",
            "Episode: 6 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 731.7152103559774 episodes steps: 1000\n",
            "Episode: 7 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 737.9310344827483 episodes steps: 1000\n",
            "Episode: 8 of 10:\n",
            "..................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "stopping due to the last 50 steps not negative rewards\n",
            "\n",
            "Total reward: 167.73293413173892 episodes steps: 658\n",
            "Episode: 9 of 10:\n",
            "........................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................................\n",
            "Total reward: 754.0145985401367 episodes steps: 1000\n",
            "10\n"
          ]
        }
      ],
      "source": [
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n",
        "model = DQN\n",
        "tmp_model_path ='./models/dql_pretrained/dql_rl_11.zip'\n",
        "loaded_model = model.load(tmp_model_path)\n",
        "\n",
        "features = {\n",
        "    \"observations\": [],\n",
        "    \"actions\": [],\n",
        "    \"rewards\": [],\n",
        "    \"dones\": [],\n",
        "}\n",
        "for episode in range(NUM_EPISODES):\n",
        "    print(f\"Episode: {episode} of {NUM_EPISODES}:\" )\n",
        "    [obs, _] = env.reset()\n",
        "    done = False\n",
        "\n",
        "    o, a, r, d = [], [], [], []\n",
        "    total_reward = 0\n",
        "    sti = 0\n",
        "    while not done:\n",
        "        sti = sti + 1\n",
        "        if sti > MAX_EPISODE_STEPS:\n",
        "            break\n",
        "\n",
        "        # if random.random() < epsilon:\n",
        "        #     action = 3# env.action_space.sample()\n",
        "        # else:\n",
        "        action, _states = loaded_model.predict(obs,deterministic=True)\n",
        "        new_obs, reward, done, t, i = env.step(action)\n",
        "        total_reward = total_reward + reward\n",
        "        oarr = prepare_observation_array(obs)\n",
        "        o.append(oarr.flatten())\n",
        "        a.append(action.item())\n",
        "        r.append(reward)\n",
        "        d.append(done)\n",
        "        obs = new_obs\n",
        "        print(\".\", end=\"\")\n",
        "\n",
        "        # check if last 50 steps does not contain a single positive reward\n",
        "        if len(r) > 100 and max(r[-50:]) <= 0:\n",
        "            # cut last 50 and set done to True\n",
        "            r = r[:-50]\n",
        "            d = d[:-50]\n",
        "            a = a[:-50]\n",
        "            d[-1] = True\n",
        "            print('\\nstopping due to the last 50 steps not negative rewards')\n",
        "            break\n",
        "    print(f\"\\nTotal reward: {total_reward} episodes steps: {len(o)}\")\n",
        "\n",
        "    features[\"observations\"].append(o)\n",
        "    features[\"actions\"].append(a)\n",
        "    features[\"rewards\"].append(r)\n",
        "    features[\"dones\"].append(d)\n",
        "\n",
        "env.close()\n",
        "print(len(features[\"actions\"]))\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bCAF3Q2meLKU"
      },
      "source": [
        "### Persist Dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "UqCjWIr2eLKU"
      },
      "outputs": [],
      "source": [
        "dataset = Dataset.from_dict(features)\n",
        "#dataset.save_to_disk('datasets/car_racing_sm/')\n",
        "\n",
        "# dataset_size = len(dataset)\n",
        "# split_point = int(0.9 * dataset_size)\n",
        "# #dataset is already shuffled\n",
        "# train_dataset = Subset(dataset, range(split_point))\n",
        "# val_dataset = Subset(dataset, range(split_point, dataset_size))\n",
        "\n",
        "dataset = {\n",
        "    'train': dataset,\n",
        "   # 'validation': val_dataset\n",
        "}\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "hSYgW1lWeLKU",
        "outputId": "069df814-9e81-41ec-81f9-379007a372ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33myakiv\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n",
            "\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Tracking run with wandb version 0.15.12"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Run data is saved locally in <code>/content/hdt/wandb/run-20231105_082240-dt_15</code>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "Resuming run <strong><a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_15' target=\"_blank\">DT_15</a></strong> to <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View project at <a href='https://wandb.ai/yakiv/CarRacingDT' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT</a>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              " View run at <a href='https://wandb.ai/yakiv/CarRacingDT/runs/dt_15' target=\"_blank\">https://wandb.ai/yakiv/CarRacingDT/runs/dt_15</a>"
            ]
          },
          "metadata": {}
        }
      ],
      "source": [
        "import toml\n",
        "# TOML-formatted string\n",
        "config_toml = \"\"\"\n",
        "PREFIX              = 'DT'\n",
        "LOG_INTERVAL        = 5\n",
        "save_steps          = 50\n",
        "num_train_epochs    = 1\n",
        "per_device_train_batch_size=64\n",
        "learning_rate       = 0.0001\n",
        "weight_decay        = 0.0001\n",
        "warmup_ratio        = 0.1\n",
        "max_grad_norm       = 0.25\n",
        "\"\"\"\n",
        "\n",
        "config_toml = toml.loads(config_toml)\n",
        "\n",
        "LOAD_SAVED_MODEL    = False\n",
        "\n",
        "RUN_NUM = 15\n",
        "WANDB_ID            = \"dt_\"+str(RUN_NUM)\n",
        "WNDB_NAME           = \"DT_\"+str(RUN_NUM)\n",
        "MODEL_SAVE_NAME     = WNDB_NAME\n",
        "SAVED_MODEL_VERSION = \"latest\"\n",
        "\n",
        "os.environ['WANDB_NOTEBOOK_NAME'] = 'DT.ipynb'\n",
        "os.environ['WANDB_MODE']='online'\n",
        "os.environ[\"WANDB_LOG_MODEL\"] = \"checkpoint\"\n",
        "os.environ[\"WANDB_DISABLED\"] = \"false\"\n",
        "\n",
        "\n",
        "wandb.login(key=\"f060d3284088ffaf4624e2de8b236f39711a99a2\")\n",
        "wandb.init(resume=WANDB_ID,\n",
        "           mode=\"online\",\n",
        "           entity=\"yakiv\",\n",
        "            project=\"CarRacingDT\",\n",
        "            #resume= \"allow\"\n",
        "            config=config_toml\n",
        "           )\n",
        "wandb.run.name = WNDB_NAME\n",
        "\n",
        "env =  gym.make('CarRacing-v2', continuous=False) #, render_mode='human'\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rmsghw2HeLKV"
      },
      "source": [
        "### Train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "2HyHbWANeLKV",
        "outputId": "12b2da30-ef13-401a-88ae-c59cf2ee5f5e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/ipykernel/ipkernel.py:283: DeprecationWarning: `should_run_async` will not call `transform_cell` automatically in the future. Please pass the result to `transformed_cell` argument and any exception that happen during thetransform in `preprocessing_exc_tuple` in IPython 7.17 and above.\n",
            "  and should_run_async(code)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'action_num': 5, 'state_dim': 27648, 'act_dim': 1, 'hidden_size': 128, 'max_ep_len': 4096, 'action_tanh': True, 'vocab_size': 1, 'n_positions': 1024, 'n_layer': 3, 'n_head': 1, 'n_inner': None, 'activation_function': 'relu', 'resid_pdrop': 0.1, 'embd_pdrop': 0.1, 'attn_pdrop': 0.1, 'layer_norm_epsilon': 1e-05, 'initializer_range': 0.02, 'scale_attn_weights': True, 'use_cache': True, 'scale_attn_by_inverse_layer_idx': False, 'reorder_and_upcast_attn': False, 'bos_token_id': 50256, 'eos_token_id': 50256, 'return_dict': True, 'output_hidden_states': False, 'output_attentions': False, 'torchscript': False, 'torch_dtype': None, 'use_bfloat16': False, 'tf_legacy_loss': False, 'pruned_heads': {}, 'tie_word_embeddings': True, 'is_encoder_decoder': False, 'is_decoder': False, 'cross_attention_hidden_size': None, 'add_cross_attention': False, 'tie_encoder_decoder': False, 'max_length': 20, 'min_length': 0, 'do_sample': False, 'early_stopping': False, 'num_beams': 1, 'num_beam_groups': 1, 'diversity_penalty': 0.0, 'temperature': 1.0, 'top_k': 50, 'top_p': 1.0, 'typical_p': 1.0, 'repetition_penalty': 1.0, 'length_penalty': 1.0, 'no_repeat_ngram_size': 0, 'encoder_no_repeat_ngram_size': 0, 'bad_words_ids': None, 'num_return_sequences': 1, 'chunk_size_feed_forward': 0, 'output_scores': False, 'return_dict_in_generate': False, 'forced_bos_token_id': None, 'forced_eos_token_id': None, 'remove_invalid_values': False, 'exponential_decay_length_penalty': None, 'suppress_tokens': None, 'begin_suppress_tokens': None, 'architectures': None, 'finetuning_task': None, 'id2label': {0: 'LABEL_0', 1: 'LABEL_1'}, 'label2id': {'LABEL_0': 0, 'LABEL_1': 1}, 'tokenizer_class': None, 'prefix': None, 'pad_token_id': None, 'sep_token_id': None, 'decoder_start_token_id': None, 'task_specific_params': None, 'problem_type': None, '_name_or_path': '', 'transformers_version': '4.35.0', 'model_type': 'decision_transformer'}\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ],
            "text/html": [
              "\n",
              "    <div>\n",
              "      \n",
              "      <progress value='1' max='1' style='width:300px; height:20px; vertical-align: middle;'></progress>\n",
              "      [1/1 00:00, Epoch 1/1]\n",
              "    </div>\n",
              "    <table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              " <tr style=\"text-align: left;\">\n",
              "      <th>Step</th>\n",
              "      <th>Training Loss</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "  </tbody>\n",
              "</table><p>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TrainOutput(global_step=1, training_loss=1.744979739189148, metrics={'train_runtime': 207.196, 'train_samples_per_second': 0.048, 'train_steps_per_second': 0.005, 'total_flos': 212410095206400.0, 'train_loss': 1.744979739189148, 'epoch': 1.0})"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ],
      "source": [
        "\n",
        "\n",
        "collator = DecisionTransformerGymDataCollator(dataset[\"train\"])\n",
        "\n",
        "config = DecisionTransformerConfig(state_dim=collator.state_dim, act_dim=collator.act_dim)\n",
        "print(config.to_dict())\n",
        "\n",
        "model = TrainableDT(config)\n",
        "\n",
        "\n",
        "training_args = TrainingArguments(\n",
        "    output_dir=\"output/\",\n",
        "    report_to=\"wandb\",\n",
        "    save_steps=config_toml[\"save_steps\"],\n",
        "    remove_unused_columns=False,\n",
        "    optim=\"adamw_torch\",\n",
        "    num_train_epochs=config_toml[\"num_train_epochs\"],\n",
        "    per_device_train_batch_size=config_toml[\"per_device_train_batch_size\"],\n",
        "    learning_rate=config_toml[\"learning_rate\"],\n",
        "    weight_decay=config_toml[\"weight_decay\"],\n",
        "    warmup_ratio=config_toml[\"warmup_ratio\"],\n",
        "    max_grad_norm=config_toml[\"max_grad_norm\"],\n",
        "    logging_steps=config_toml[\"LOG_INTERVAL\"],\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=training_args,\n",
        "    train_dataset=dataset[\"train\"],\n",
        "    data_collator=collator,\n",
        "\n",
        ")\n",
        "\n",
        "trainer.train()\n"
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "V100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}